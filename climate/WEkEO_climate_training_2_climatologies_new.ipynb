{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='./img/LogoWekeo_Copernicus_RGB_0.png' align='right' width='20%'></img>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial on climatologies and trends\n",
    "In this tutorial we will use the WEkEO Jupyterhub to access and analyse data from the Climate Data Store (CDS) of the Copernicus Climate Change Service (C3S). The tutorial comprises the following steps:\n",
    "\n",
    "1. [Search and download](#search_download) data using the CDS API: We will focus on ERA5 reanalysis data of 2 metre (near-surface) temperature.\n",
    "2. [Read data](#read_data): Once downloaded, we will read and understand the data, including its variables and coordinates.\n",
    "3. [View and plot data](#view_plot): We will see how the mean temperature varies globally, and how the Earth is warming by plotting time-series of global anomalies.\n",
    "4. [Analyse data](#analyse_data) over the Arctic: We will focus on a subset over the Arctic and compare the rate of warming between seasons."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='./img/map_1month_anomaly_Global_ea_2t_202010_title.jpg' align='center' width='100%'></img>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='search_download'></a>1. Search and download data\n",
    "\n",
    "Before we begin we must prepare our environment. This includes installing the Application Programming Interface (API) of the CDS, and importing the various python libraries that we will need.\n",
    "\n",
    "#### Install CDS API\n",
    "\n",
    "To install the CDS API, run the following command. We use an exclamation mark to pass the command to the shell (not to the Python interpreter)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install cdsapi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import libraries\n",
    "\n",
    "We will be working with data in NetCDF format. To best handle this data we will use libraries for working with multidimensional arrays, in particular Xarray. We will also need libraries for plotting and viewing data, in this case we will use Matplotlib and Cartopy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CDS API\n",
    "import cdsapi\n",
    "\n",
    "# Libraries for working with multidimensional arrays\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "\n",
    "# Libraries for plotting and visualising data\n",
    "import matplotlib.path as mpath\n",
    "import matplotlib.pyplot as plt\n",
    "import cartopy.crs as ccrs\n",
    "from cartopy.mpl.gridliner import LONGITUDE_FORMATTER, LATITUDE_FORMATTER\n",
    "import cartopy.feature as cfeature\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import json\n",
    "from zipfile import ZipFile\n",
    "import time\n",
    "import base64\n",
    "from IPython.core.display import HTML\n",
    "\n",
    "import requests\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a id='read_data'></a> Select Option 1 (WEkEO API) or Option 2 (CDS API)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='read_data'></a> Option 1 WEkEO API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Install the WEkEO HDA client"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The WEkEO HDA client is a python based library. It provides support for both Python 2.7.x and Python 3."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to install the WEkEO HDA client via the package management system pip, you have to running on Unix/Linux the command shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install -U hda"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please verify the following requirements are installed before skipping to the next step:\n",
    "   - Python 3\n",
    "   - requests\n",
    "   - tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load WEkEO HDA client"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The hda client provides a fully compliant Python 3 client that can be used to search and download products using the Harmonized Data Access WEkEO API.\n",
    "HDA is RESTful interface allowing users to search and download WEkEO datasets.\n",
    "Documentation about its usage can be found at https://www.wekeo.eu/."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hda import Client"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get the API request"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each dataset on WEkEO is assigned a unique `datasetId`. Let us store the dataset ID for `ERA5 monthly averaged data on single levels from 1979 to present` as a variable called `dataset_id` to be used later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_id = \"EO:ECMWF:DAT:REANALYSIS_ERA5_SINGLE_LEVELS_MONTHLY_MEANS\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Configure the WEkEO API Authentication"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to interact with WEkEO's Harmonised Data Access API, each user first makes sure the file \"$HOME/.hdarc\" exists with the URL to the API end point and your user and password.\n",
    "\n",
    "For example, to search for the file .hdarc in the $HOME diretory, the user would open a terminale and run the following command:"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "find $HOME -type f -name .hdarc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then he could copy the code below in the file \"$HOME/.hdarc\" (in your Unix/Linux environment) and adapt the following template with the credentials of your WEkEO account:"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# your URL and WEkEO API username and password (needs to be in '  ')\n",
    "url: 'https://wekeo-broker.apps.mercator.dpi.wekeo.eu/databroker'\n",
    "user_name = '#############'\n",
    "password = '#############'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If he doesn't have a WEkEO account, please self register at the WEkEO registration page https://my.wekeo.eu/web/guest/user-registration."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load data descriptor file and request data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Harmonised Data Access API can read your data request from a dictionary. In this dictionary, you can describe the dataset you are interested in downloading."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {\n",
    "  \"datasetId\": \"EO:ECMWF:DAT:REANALYSIS_ERA5_SINGLE_LEVELS_MONTHLY_MEANS\",\n",
    "  \"boundingBoxValues\": [\n",
    "    {\n",
    "      \"name\": \"area\",\n",
    "      \"bbox\": [\n",
    "        -180,\n",
    "        -90,\n",
    "        180,\n",
    "        90\n",
    "      ]\n",
    "    }\n",
    "  ],\n",
    "  \"stringChoiceValues\": [\n",
    "    {\n",
    "      \"name\": \"format\",\n",
    "      \"value\": \"netcdf\"\n",
    "    }\n",
    "  ],\n",
    "  \"multiStringSelectValues\": [\n",
    "    {\n",
    "      \"name\": \"time\",\n",
    "      \"value\": [\n",
    "        \"00:00\"\n",
    "      ]\n",
    "    },\n",
    "    {\n",
    "      \"name\": \"day\",\n",
    "      \"value\": [\n",
    "        \"01\"\n",
    "      ]\n",
    "    },\n",
    "    {\n",
    "      \"name\": \"month\",\n",
    "      \"value\": [\n",
    "        \"10\",\n",
    "        \"11\",\n",
    "        \"12\",\n",
    "        \"01\",\n",
    "        \"02\",\n",
    "        \"03\",\n",
    "        \"09\",\n",
    "        \"06\",\n",
    "        \"05\",\n",
    "        \"08\",\n",
    "        \"07\",\n",
    "        \"04\"\n",
    "      ]\n",
    "    },\n",
    "    {\n",
    "      \"name\": \"product_type\",\n",
    "      \"value\": [\n",
    "        \"monthly_averaged_reanalysis\"\n",
    "      ]\n",
    "    },\n",
    "    {\n",
    "      \"name\": \"variable\",\n",
    "      \"value\": [\n",
    "        \"2m_temperature\"\n",
    "      ]\n",
    "    },\n",
    "    {\n",
    "      \"name\": \"year\",\n",
    "      \"value\": [\n",
    "        \"1979\",\n",
    "        \"1980\",\n",
    "        \"1981\",\n",
    "        \"1982\",\n",
    "        \"1983\",\n",
    "        \"1984\",\n",
    "        \"1985\",\n",
    "        \"1986\",\n",
    "        \"1987\",\n",
    "        \"1988\",\n",
    "        \"1989\",\n",
    "        \"1990\",\n",
    "        \"1991\",\n",
    "        \"1992\",\n",
    "        \"1993\",\n",
    "        \"1994\",\n",
    "        \"1995\",\n",
    "        \"1996\",\n",
    "        \"1997\",\n",
    "        \"1998\",\n",
    "        \"1999\",\n",
    "        \"2000\",\n",
    "        \"2001\",\n",
    "        \"2002\",\n",
    "        \"2003\",\n",
    "        \"2004\",\n",
    "        \"2005\",\n",
    "        \"2006\",\n",
    "        \"2007\",\n",
    "        \"2008\",\n",
    "        \"2009\",\n",
    "        \"2010\",\n",
    "        \"2011\",\n",
    "        \"2012\",\n",
    "        \"2013\",\n",
    "        \"2014\",\n",
    "        \"2015\",\n",
    "        \"2016\",\n",
    "        \"2017\",\n",
    "        \"2018\",\n",
    "        \"2019\"\n",
    "      ]\n",
    "    }\n",
    "  ]\n",
    "}\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Download requested data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a final step, you can use directly the client to download data as in following example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = Client(debug=True)\n",
    "\n",
    "matches = c.search(data)\n",
    "print(matches)\n",
    "matches.download()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='read_data'></a> Option 2 CDS API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Enter your CDS API key\n",
    "\n",
    "Before you can request data from the CDS, you will need to register on the CDS website and obtain a User ID and API Key. In order to do so, please follow the steps at this link:\n",
    "https://cds.climate.copernicus.eu/api-how-to\n",
    "\n",
    "Once you have a User ID and API Key, please enter them in the fields below by replacing \"UID\" with your User ID, and API_KEY with your API Key."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!echo \"url: https://cds.climate.copernicus.eu/api/v2\" > ~/.cdsapirc\n",
    "!echo \"key: UID:API_KEY\" >> ~/.cdsapirc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Search for data\n",
    "\n",
    "To search for data, visit the CDS website: http://cds.climate.copernicus.eu\n",
    "Here you can search for ERA5 data using the search bar. The data we need for this tutorial is the ERA5 monthly averaged data on single levels from 1979 to present.\n",
    "\n",
    "<img src='./img/CDS.jpg' align='left' width='45%'></img> <img src='./img/CDS_ERA5.jpg' align='right' width='45%'></img> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Having selected the correct dataset, we now need to specify what product type, variables, temporal and geographic coverage we are interested in. These can all be selected in the **\"Download data\"** tab. In this tab a form appears in which we will select the following parameters to download:\n",
    "\n",
    "- Product type: `Monthly averaged reanalysis`\n",
    "- Variable: `2m temperature`\n",
    "- Year: `1979 to 2019`\n",
    "- Month: `all`\n",
    "- Time: `00:00` (default)\n",
    "- Geographical area: `Whole available region` \n",
    "- Format: `NetCDF`\n",
    "\n",
    "<img src='./img/Notebook2_data.png' align='center' width='100%'></img>\n",
    "\n",
    "At the end of the download form, select **\"Show API request\"**. This will reveal a block of code, which you can simply copy and paste into a cell of your Jupyter Notebook (see cell below) ...\n",
    "\n",
    "#### Download data\n",
    "\n",
    "... having copied the API request into the cell below, running this will retrieve and download the data you requested into your local directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = cdsapi.Client()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c.retrieve(\n",
    "    'reanalysis-era5-single-levels-monthly-means',\n",
    "    {\n",
    "        'product_type': 'monthly_averaged_reanalysis',\n",
    "        'variable': '2m_temperature',\n",
    "        'year': [\n",
    "            '1979', '1980', '1981',\n",
    "            '1982', '1983', '1984',\n",
    "            '1985', '1986', '1987',\n",
    "            '1988', '1989', '1990',\n",
    "            '1991', '1992', '1993',\n",
    "            '1994', '1995', '1996',\n",
    "            '1997', '1998', '1999',\n",
    "            '2000', '2001', '2002',\n",
    "            '2003', '2004', '2005',\n",
    "            '2006', '2007', '2008',\n",
    "            '2009', '2010', '2011',\n",
    "            '2012', '2013', '2014',\n",
    "            '2015', '2016', '2017',\n",
    "            '2018', '2019',\n",
    "        ],\n",
    "        'month': [\n",
    "            '01', '02', '03',\n",
    "            '04', '05', '06',\n",
    "            '07', '08', '09',\n",
    "            '10', '11', '12',\n",
    "        ],\n",
    "        'time': '00:00',\n",
    "        'format': 'netcdf',\n",
    "    },\n",
    "    'era5_monthly_t2m.nc')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='read_data'></a>2. Read Data\n",
    "\n",
    "Now that we have downloaded the data, we can start to play ...\n",
    "\n",
    "We have requested the data in NetCDF format. This is a commonly used format for array-oriented scientific data. \n",
    "\n",
    "To read and process this data we will make use of the Xarray library. Xarray is an open source project and Python package that makes working with labelled multi-dimensional arrays simple, efficient, and fun! We will read the data from our NetCDF file into an Xarray **\"dataset\"**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Option WEkEO API\n",
    "#t2m = 'adaptor.mars.internal-1620660966.2440398-21838-1-358b5373-8d57-4d0e-9cab-e2a69d22287d.nc'#OLD\n",
    "t2m = 'adaptor.mars.internal-1636125601.5956395-5521-10-ed21bbeb-658c-4139-b00e-9ce6b0e8ba90.nc'\n",
    "# Option CDS API (Comment Out)\n",
    "#t2m = 'era5_monthly_t2m.nc'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Xarray Dataset\n",
    "ds = xr.open_dataset(t2m)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can query our newly created Xarray dataset ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that the dataset has one variable called **\"t2m\"**, which stands for \"2 metre temperature\", and three coordinates of **longitude**, **latitude** and **time**.\n",
    "\n",
    "While an Xarray **dataset** may contain multiple variables, an Xarray **data array** holds a single multi-dimensional variable and its coordinates. To make the processing of the **t2m** data easier, we convert in into an Xarray data array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Xarray Data Array\n",
    "da = ds['t2m']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='view_plot'></a>3. View and plot data\n",
    "\n",
    "Now the fun part begins! Once our data is in the right format, there is no limit to what we can do with it! For example we can finally visualise the data to see what information it can provide.\n",
    "\n",
    "#### View temporal mean for reference period\n",
    "\n",
    "We will begin by creating a variable with the yearly means. Then we will extract the mean value for each geographic latitude and longitude for the period from 1981 to 2010. We will use this as a **reference period** with which to calculate **anomalies**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a variable with the yearly means:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yearly_mean = da.groupby('time.year').mean('time')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate mean temperature for a reference period of 1981 to 2010:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ref = yearly_mean.where((yearly_mean.year > 1980) & (yearly_mean.year < 2011), drop=True)\n",
    "ref_mean = ref.mean(dim=\"year\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us plot this to see how the mean temperature for this period varies globally:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ref_mean.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice the strong latitude gradient, and cold regions such as the Tibetan Plateau, the Andes and Greenland.\n",
    "\n",
    "#### Plot global anomalies\n",
    "\n",
    "We will now plot a global time series of annual temperature anomalies, defined as deviations in temperature from the reference mean."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate the global mean for the reference period (1981 to 2010), and for the annual data from 1979 to 2019:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# global mean for reference period\n",
    "ref_global = ref_mean.mean([\"longitude\", \"latitude\"])\n",
    "\n",
    "# global mean for annual data\n",
    "yearly_mean_global = yearly_mean.mean([\"longitude\", \"latitude\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now derive the anomalies by subtracting the global mean for the reference period from the annual means:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anomalies_global = yearly_mean_global - ref_global"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's plot the annual global temperature anomalies over time, to see if there are any trends."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dashed horizontal line to show where the reference temperature lies\n",
    "mean_line = xr.DataArray(0.0, coords=[('year', np.arange(1981,2010))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(8,5))\n",
    "ax = plt.subplot()\n",
    "ax.set_ylabel('t2m anomaly (Kelvin)')\n",
    "ax.set_xlabel('year')\n",
    "ax.plot(anomalies_global.year, anomalies_global, color='green', label='Global anomalies')\n",
    "ax.plot(mean_line.year, mean_line, color='red', linestyle='dashed', label='Mean anomaly 1981-2019')\n",
    "handles, labels = ax.get_legend_handles_labels()\n",
    "ax.legend(handles, labels)\n",
    "ax.set_title('Global anomalies of t2m from 1979 to 2019')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice a clear trend in global temperature!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='analyse_data'></a>4. Analyse data over the Arctic\n",
    "We will now focus our attention over the Arctic. Here we will repeat the analysis above for this subset area. In addition, we will compare variations in the mean temperature of different seasons throughout the time series."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot mean Arctic temperature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we have to create a subset for the Arctic Circle (above lat 66°33'N, or 66.55 in decimal degrees)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arctic = da.where(da.latitude >= 66.55, drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate mean 2 metre temperature in period 1979 to 2019:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arctic_mean_1979_to_2019 = arctic.mean(dim=\"time\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's plot this data in a map projection that facilitates visualisation of the Arctic:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the figure panel \n",
    "fig = plt.figure(figsize=(5,5))\n",
    "# create the map using the cartopy Orthographic projection, selecting the North Pole\n",
    "ax = plt.subplot(1,1,1, projection=ccrs.Orthographic(central_latitude=90.0))\n",
    "# add coastlines\n",
    "ax.coastlines()\n",
    "# compute a circle in axes coordinates, which we can use as a boundary for the map.\n",
    "theta = np.linspace(0, 2*np.pi, 100)\n",
    "center, radius = [0.5, 0.5], 0.5\n",
    "verts = np.vstack([np.sin(theta), np.cos(theta)]).T\n",
    "circle = mpath.Path(verts * radius + center)\n",
    "# set boundary\n",
    "ax.set_extent([-180,180, 66.55,90], crs=ccrs.PlateCarree())\n",
    "ax.set_boundary(circle, transform=ax.transAxes)\n",
    "# provide a title\n",
    "ax.set_title('Mean Arctic t2m for period 1979 to 2019')\n",
    "# plot t2m\n",
    "pp = plt.pcolormesh(arctic_mean_1979_to_2019.longitude, arctic_mean_1979_to_2019.latitude,\n",
    "                    arctic_mean_1979_to_2019, cmap='viridis', transform=ccrs.PlateCarree())\n",
    "# add colourbar\n",
    "cbar = plt.colorbar(pp)\n",
    "cbar.set_label(label='t2m (Kelvin)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot monthly time series\n",
    "Let's plot the monthly time series to see if we can identify any trends."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arctic_mean = arctic.mean([\"longitude\", \"latitude\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arctic_mean.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Can you identify any global warming? The strong seasonal variations are evident throughout each year, but it is difficult to see any clear long-term trends."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot yearly time series\n",
    "Now let's plot a time series of yearly averages. By removing the seasonal variations, perhaps we can identify some long-term trends."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arctic_yearly_mean = arctic_mean.groupby('time.year').mean('time')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arctic_yearly_mean.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can clearly see a positive trend in warming throughout the time-series!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot seasonal time series\n",
    "\n",
    "It may be interesting to compare trends in the mean temperature of different seasons throughout the time series. Do they vary? Are some seasons more constant over time, while others fluctuate?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create rolling average of three months\n",
    "arctic_roll = arctic_mean.rolling(time=3, center=True).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAM = arctic_roll[3:-8:12] # MAM = March, April, May (Spring)\n",
    "JJA = arctic_roll[6:-5:12] # JJA = June, July, August (Summer)\n",
    "SON = arctic_roll[9:-2:12] # SON = September, October, November (Autumn)\n",
    "DJF = arctic_roll[12:-11:12] # DJF = December, January, February (Winter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(5,5))\n",
    "ax = plt.subplot()\n",
    "ax.set_ylabel('t2m (Kelvin)')\n",
    "ax.set_xlabel('year')\n",
    "ax.plot(MAM.time, MAM, color='green', label='Spring')\n",
    "ax.plot(JJA.time, JJA, color='red', label='Summer')\n",
    "ax.plot(SON.time, SON, color='orange', label='Autumn')\n",
    "ax.plot(DJF.time, DJF, color='blue', label='Winter')\n",
    "ax.set_title('Arctic seasonal t2m mean')\n",
    "handles, labels = ax.get_legend_handles_labels()\n",
    "ax.legend(handles, labels, bbox_to_anchor=(1, 1), loc='upper left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note the difference in variability of seasonal mean t2m throughout the time series: mean summer temperatures are more constant than in other seasons."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p><img src='./img/all_partners_wekeo.png' align='left' alt='Logo EU Copernicus' width='100%'></img></p>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
