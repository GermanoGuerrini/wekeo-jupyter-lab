{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='./img/LogoWekeo_Copernicus_RGB_0.png' align='right' width='20%'></img>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial: analysis of climate extremes\n",
    "In this tutorial we will use the WEkEO Jupyterhub to access and analyse data from the Wekeo HDA API Client of the Copernicus Climate Change Service (C3S). We will analyse climate extremes, and focus on the area surrounding the city of Lille in Northern France.\n",
    "\n",
    "The tutorial comprises the following steps:\n",
    "\n",
    "1. [Search and download data](#search_download) data using the CDS API: We will focus on ERA5 reanalysis data of 2 metre (near-surface) temperature.\n",
    "2. [Read data](#read_data): Once downloaded, we will read and understand the data, including its variables and coordinates.\n",
    "3. [View and plot](#view_plot) maximum temperatures in September 2020.\n",
    "4. [Calculate averages](#calculate_averages) of the maximum daily temperatures in September over the period from 1979 to 2019, and compare these with our findings for 2020."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='./img/climate_extremes.png' align='center' width='100%'></img>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='search_download'></a>1. Search and download data\n",
    "\n",
    "Before we begin we must prepare our environment. This includes installing the Application Programming Interface (API) of the CDS, and importing the various python libraries that we will need.\n",
    "\n",
    "#### Install HDA API\n",
    "\n",
    "To install the HDA API, run the following command. We use an exclamation mark to pass the command to the shell (not to the Python interpreter)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install -U hda"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please verify the following requirements are installed before skipping to the next step:\n",
    "   - Python 3\n",
    "   - requests\n",
    "   - tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import libraries\n",
    "\n",
    "We will be working with data in NetCDF format. To best handle this data we need a number of libraries for working with multidimensional arrays, in particular Xarray. We will also need libraries for plotting and viewing data, in particular Matplotlib and Cartopy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libraries for working with multidimensional arrays\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "\n",
    "# Libraries for plotting and visualising data\n",
    "import matplotlib.path as mpath\n",
    "import matplotlib.pyplot as plt\n",
    "import cartopy.crs as ccrs\n",
    "from cartopy.mpl.gridliner import LONGITUDE_FORMATTER, LATITUDE_FORMATTER\n",
    "import cartopy.feature as cfeature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The hda client provides a fully compliant Python 3 client that can be used to search and download products using the Harmonized Data Access WEkEO API.\n",
    "HDA is RESTful interface allowing users to search and download WEkEO datasets.\n",
    "Documentation about its usage can be found at https://www.wekeo.eu/."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hda import Client"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Search for data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Under [WEkEO DATA](https://wekeo.eu/data?view=catalogue). Clicking the + to add a layer, opens a catalogue search. Here you can use free text, or you can use the filter options on the left to refine your search and look by satellite plaform, sensor, Copernicus service, area (region of interest), general time period (past or future), as well as through a variety of flags.\n",
    "\n",
    "You can click on the dataset you are interested in and you will be guided to a range of details including the dataset temporal and spatial extent, collection ID, and metadata.\n",
    "\n",
    "Now search for the product `ERA5 hourly data on single levels from 1979 to present`. You can find it more easily by selecting 'ERA5 hourly data on single' in the 'COPERNICUS SERVICE' filter group. \n",
    "\n",
    "Once you have found it, select 'Details' to read the dataset description.\n",
    "\n",
    "<br>\n",
    "\n",
    "<div style='text-align:center;'>\n",
    "<figure><img src='./img/WEKEO_ERA5_hourly_data.png' width='70%' />\n",
    "    <figcaption><i>WEkEO interface to search for datasets</i></figcaption>\n",
    "</figure>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset description provides the following information:\n",
    "- **Abstract**, containing a general description of the dataset,\n",
    "- **Classification**, including the Dataset ID \n",
    "- **Resources**, such as a link to the Product Data Format Specification guide, and JSON metadata\n",
    "- **Contacts**, where you can find further information about the data source from its provider.  \n",
    "\n",
    "You need the `Dataset ID` to request data from the Harmonised Data Access API. \n",
    "\n",
    "<br>\n",
    "\n",
    "<div style='text-align:center;'>\n",
    "<figure><img src='./img/ERA5_hourly_info.png' width='50%' />\n",
    "    <figcaption><i>Dataset information on WEkEO</i></figcaption>\n",
    "</figure>\n",
    "</div>\n",
    "<br>\n",
    "\n",
    "Let's store the Dataset ID as a variable called `dataset_id` to be used later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_id = \"EO:ECMWF:DAT:REANALYSIS_ERA5_SINGLE_LEVELS\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now select `Add to map` in the data description to add the selected dataset to the list of layers in your map view. Once the dataset appears as a layer, select the `subset and download` icon. This will enable you to specify the variables, temporal and in some cases geographic extent of the data you would like to download. Select the dataset information and then select `NetCDF` as format.\n",
    "\n",
    "Now select `Show API request`. This will show the details of your selection in `JSON` format. If you now select `Copy`, you can copy these details to the clipboard then paste it either into a text file to create a `JSON` file (see example [here](./SeaLevel_data_descriptor.json)), or paste it directly into the cell below.\n",
    "\n",
    "The Harmonised Data Access API can read this information, which is in the form of a dictionary.\n",
    "\n",
    "<br>\n",
    "\n",
    "<div style='text-align:center;'>\n",
    "<figure><img src='./img/ERA5_hourly_params_json.png' width='60%' />\n",
    "    <figcaption><i>Displaying a JSON query from a request made to the Harmonised Data Access API through the data portal</i></figcaption>\n",
    "</figure>\n",
    "</div>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Configure the WEkEO API Authentication"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to interact with WEkEO's Harmonised Data Access API, each user first makes sure the file \"$HOME/.hdarc\" exists with the URL to the API end point and your user and password.\n",
    "\n",
    "For example, to search for the file .hdarc in the $HOME diretory, the user would open a terminale and run the following command:"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "find $HOME -type f -name .hdarc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then he could copy the code below in the file \"$HOME/.hdarc\" (in your Unix/Linux environment) and adapt the following template with the credentials of your WEkEO account:"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# your URL and WEkEO API username and password (needs to be in '  ')\n",
    "url: 'https://wekeo-broker.apps.mercator.dpi.wekeo.eu/databroker'\n",
    "user_name = '#############'\n",
    "password = '#############'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If he doesn't have a WEkEO account, please self register at the WEkEO registration page https://my.wekeo.eu/web/guest/user-registration."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load data descriptor file and request data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Harmonised Data Access API can read your data request from a dictionary. In this dictionary, you can describe the dataset you are interested in downloading."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data ={\n",
    "  \"datasetId\": \"EO:ECMWF:DAT:REANALYSIS_ERA5_SINGLE_LEVELS\",\n",
    "  \"boundingBoxValues\": [\n",
    "    {\n",
    "      \"name\": \"area\",\n",
    "      \"bbox\": [\n",
    "        51,\n",
    "        3,\n",
    "        50,\n",
    "        4\n",
    "      ]\n",
    "    }\n",
    "  ],\n",
    "  \"stringChoiceValues\": [\n",
    "    {\n",
    "      \"name\": \"format\",\n",
    "      \"value\": \"netcdf\"\n",
    "    }\n",
    "  ],\n",
    "  \"multiStringSelectValues\": [\n",
    "    {\n",
    "      \"name\": \"product_type\",\n",
    "      \"value\": [\n",
    "        \"reanalysis\"\n",
    "      ]\n",
    "    },\n",
    "    {\n",
    "      \"name\": \"year\",\n",
    "      \"value\": [\n",
    "        \"1979\",\n",
    "        \"1980\",\n",
    "        \"1981\",\n",
    "        \"1982\",\n",
    "        \"1983\",\n",
    "        \"1984\",\n",
    "        \"1985\",\n",
    "        \"1986\",\n",
    "        \"1987\",\n",
    "        \"1988\",\n",
    "        \"1989\",\n",
    "        \"1990\",\n",
    "        \"1991\",\n",
    "        \"1992\",\n",
    "        \"1993\",\n",
    "        \"1994\",\n",
    "        \"1995\",\n",
    "        \"1996\",\n",
    "        \"1997\",\n",
    "        \"1998\",\n",
    "        \"1999\",\n",
    "        \"2000\",\n",
    "        \"2001\",\n",
    "        \"2002\",\n",
    "        \"2003\",\n",
    "        \"2004\",\n",
    "        \"2005\",\n",
    "        \"2006\",\n",
    "        \"2007\",\n",
    "        \"2008\",\n",
    "        \"2009\",\n",
    "        \"2010\",\n",
    "        \"2011\",\n",
    "        \"2012\",\n",
    "        \"2013\",\n",
    "        \"2014\",\n",
    "        \"2015\",\n",
    "        \"2016\",\n",
    "        \"2017\",\n",
    "        \"2018\",\n",
    "        \"2019\",\n",
    "        \"2020\"\n",
    "      ]\n",
    "    },\n",
    "    {\n",
    "      \"name\": \"variable\",\n",
    "      \"value\": [\n",
    "        \"2m_temperature\"\n",
    "      ]\n",
    "    },\n",
    "    {\n",
    "      \"name\": \"month\",\n",
    "      \"value\": [\n",
    "        \"09\"\n",
    "      ]\n",
    "    },\n",
    "    {\n",
    "      \"name\": \"day\",\n",
    "      \"value\": [\n",
    "        \"10\",\n",
    "        \"11\",\n",
    "        \"12\",\n",
    "        \"13\",\n",
    "        \"14\",\n",
    "        \"15\",\n",
    "        \"16\",\n",
    "        \"17\",\n",
    "        \"18\",\n",
    "        \"19\",\n",
    "        \"20\",\n",
    "        \"21\",\n",
    "        \"22\",\n",
    "        \"23\",\n",
    "        \"24\",\n",
    "        \"25\",\n",
    "        \"26\",\n",
    "        \"27\",\n",
    "        \"28\",\n",
    "        \"29\",\n",
    "        \"30\",\n",
    "        \"01\",\n",
    "        \"02\",\n",
    "        \"03\",\n",
    "        \"04\",\n",
    "        \"05\",\n",
    "        \"06\",\n",
    "        \"07\",\n",
    "        \"08\",\n",
    "        \"09\"\n",
    "      ]\n",
    "    },\n",
    "    {\n",
    "      \"name\": \"time\",\n",
    "      \"value\": [\n",
    "        \"00:00\",\n",
    "        \"04:00\",\n",
    "        \"08:00\",\n",
    "        \"12:00\",\n",
    "        \"16:00\",\n",
    "        \"20:00\",\n",
    "        \"01:00\",\n",
    "        \"05:00\",\n",
    "        \"09:00\",\n",
    "        \"13:00\",\n",
    "        \"17:00\",\n",
    "        \"21:00\",\n",
    "        \"02:00\",\n",
    "        \"06:00\",\n",
    "        \"10:00\",\n",
    "        \"14:00\",\n",
    "        \"18:00\",\n",
    "        \"22:00\",\n",
    "        \"03:00\",\n",
    "        \"07:00\",\n",
    "        \"11:00\",\n",
    "        \"15:00\",\n",
    "        \"19:00\",\n",
    "        \"23:00\"\n",
    "      ]\n",
    "    }\n",
    "  ]\n",
    "}\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Download requested data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a final step, you can use directly the client to download data as in following example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = Client(debug=True)\n",
    "\n",
    "matches = c.search(data)\n",
    "print(matches)\n",
    "matches.download()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='read_data'></a>2. Read Data\n",
    "\n",
    "Now that we have downloaded the data, we can start to play ...\n",
    "\n",
    "We have requested the data in NetCDF format. This is a commonly used format for array-oriented scientific data. \n",
    "\n",
    "To read and process this data we will make use of the Xarray library. Xarray is an open source project and Python package that makes working with labelled multi-dimensional arrays simple, efficient, and fun! We will read the data from our NetCDF file into an Xarray **\"dataset\"**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = r'./adaptor.mars.internal-1639129639.6692817-20965-2-bc1c1491-3311-42aa-b3de-5ba948fac15d.nc'\n",
    "# Create Xarray Dataset\n",
    "ds = xr.open_dataset(filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can query our newly created Xarray dataset ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that the dataset has one variable called **\"t2m\"**, which stands for \"2 metre temperature\", and four coordinates of **longitude**, **latitude**, **expver** and **time**. Expver stands for 'experiment version'. Data up until the end of 2019 has expver value of 1. This is referred to as \"operational data\", while more recent data from 2020 has expver value of 5, which is near-real time data. After a period of time, near-real time data passes to the operational dataset.\n",
    "\n",
    "Select the icons to the right of the table above to expand the attributes of the coordinates and data variables. What are the units of the temperature data?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While an Xarray **dataset** may contain multiple variables, an Xarray **data array** holds a single variable (which may still be multi-dimensional) and its coordinates. To make the processing of the **t2m** data easier, we convert in into an Xarray data array:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "da = ds['t2m']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's convert the units of the 2m temperature data from Kelvin to degrees Celsius. The formula for this is simple: degrees Celsius = Kelvin - 273.15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t2m_C = da - 273.15"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='view_plot'></a>3. View daily maximum 2m temperature for September 2020\n",
    "We will plot the maximum values of 2m temperature over the subset area of Northern France."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we average over the subset area:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Lille_t2m = t2m_C.mean([\"longitude\", \"latitude\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we select only the data for 2020, and only experiment version 5 (near-real time version of ERA5):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Lille_2020 = Lille_t2m.sel(expver=5)\n",
    "Lille_2020 = Lille_2020.sel(time='2020')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now calculate the max daily 2m temperature for each day in September 2020:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Lille_2020_max = Lille_2020.groupby('time.day').max('time')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's plot the results in a chart:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = Lille_2020_max.day\n",
    "y = (np.around(Lille_2020_max.values, 0)).astype(int)\n",
    "\n",
    "fig = plt.figure(figsize=(10,5))\n",
    "ax = plt.subplot()\n",
    "ax.set_ylabel('t2m (Celsius)')\n",
    "ax.set_xlabel('day')\n",
    "ax.plot(x, y)\n",
    "ax.grid(linestyle='--')\n",
    "for i,j in zip(x,y):\n",
    "    ax.annotate(str(j),xy=(i,j))\n",
    "ax.set_title('Max daily t2m for Sep 2020')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('The maximum temperature in September 2020 in this area was', \n",
    "      np.around(Lille_2020_max.max().values, 1), 'degrees Celsius.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which day in September had the highest maximum temperature?\n",
    "\n",
    "Is this typical for Northern France? How does this compare with the long term average? We will seek to answer these questions in the next section."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='calculate_averages'></a>4. Calculate long term average of 2m temperature for September over Northern France\n",
    "We will now seek to discover just how high the temperature for Lille in mid September 2020 was when compared to typical values exptected in this region at this time of year. To do that we will calculate the mean and standard deviation of maximum daily 2m temperature for each day in September for the period of 1979 to 2019, and compare these with our values for 2020."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we select all data prior to 2020. This data has experiment version 1 (consolidated version of ERA5)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Lille_past = Lille_t2m.sel(expver=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we calculate the climatology for this data, i.e. the mean and standard deviation of maximum daily values for each of the days in September for a period of several decades (from 1979 to 2019)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To do this, we first have to extract the maximum daily value for each day in the time series:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Lille_max = Lille_past.resample(time='D').max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we can calculate the mean and standard deviation of this for the 40 year time series for each day in September:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Lille_m = Lille_max.groupby('time.day').mean('time')\n",
    "Lille_sd = Lille_max.groupby('time.day').std('time')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's plot this data. We will plot the mean plus and minus one standard deviation to have an idea of the expected range of maximum daily temperatures in this part of France in September:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y1 = Lille_m\n",
    "y2 = Lille_m + Lille_sd\n",
    "y2 = np.squeeze(y2.values)\n",
    "y3 = Lille_m - Lille_sd\n",
    "y3 = np.squeeze(y3.values)\n",
    "\n",
    "fig = plt.figure(figsize=(10,5))\n",
    "ax = plt.subplot()\n",
    "ax.set_ylabel('t2m (Celsius)')\n",
    "ax.set_xlabel('day')\n",
    "ax.plot(Lille_m.day, y1, color='green', label='t2m mean, shading: +/- SD')\n",
    "ax.plot(Lille_m.day, y2, color='white')\n",
    "ax.plot(Lille_m.day, y3, color='white')\n",
    "ax.fill_between(Lille_m.day, y2, y3, alpha=0.1)\n",
    "handles, labels = ax.get_legend_handles_labels()\n",
    "ax.legend(handles, labels)\n",
    "ax.set_title('t2m climatology for Sep from 1979 to 2019')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is the typical range of maximum 2m temperature values for September 15?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now look more closely at the probability distribution of maximum temperatures for 15 September in this time period. To do this, we will first select only the max daily temperature for 15 September, for each year in the time series:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Lille_max = Lille_max.dropna('time', how='all')\n",
    "Lille_15 = Lille_max[14::30]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will then plot the histogram of this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Lille_15.plot.hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Look at the range of maximum temperatures for 15 September in the period from 1979 to 2019. Has the temperature in this period ever exceeded that of 15 September 2020?\n",
    "\n",
    "The histogram shows the distribution of maximum temperature of one day in each year of the time series, which corresponds to 41 samples. In order to increase the number of samples, let's plot the histogram of maximum temperatures on 15 September, plus or minus three days. This would increase our number of samples by a factor of seven.\n",
    "\n",
    "To do this, we first need to produce an index that takes 15 Sep, plus or minus three days, from every year in the time series:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "years = np.arange(41)\n",
    "days_in_sep = np.arange(11,18)\n",
    "index = np.zeros(287)\n",
    "for i in years:\n",
    "    index[i*7:(i*7)+7] = days_in_sep + (i*30)\n",
    "index = index.astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we apply this index to filter the array of max daily temperature from 1979 to 2019: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Lille_7days = Lille_max.values[index]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can plot the histogram of maximum daily temperatures in days 12-18 September from 1979-2019:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,5))\n",
    "plt.hist(Lille_7days, bins = np.arange(10,32,1)) \n",
    "plt.title(\"histogram of max temperature in days 12-18 Sep from 1979-2019\")\n",
    "plt.xticks(np.arange(10,32,1))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Even in this increased temporal range, the maximum daily temperature still never reached that of 15 September 2020!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p><img src='./img/all_partners_wekeo.png' align='left' alt='Logo EU Copernicus' width='100%'></img></p>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
